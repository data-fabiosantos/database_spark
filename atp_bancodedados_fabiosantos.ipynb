{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnpxVaaIypWTyv9rlMAoWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-fabiosantos/database_spark/blob/main/atp_bancodedados_fabiosantos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PUCPR - PONTIFÍCIA UNIVERSIDADE CATÓLICA DO PARANÁ\n",
        "# CURSO: BIG DATA E INTELIGÊNCIA ANALÍTICA\n",
        "# MATÉRIA: BANCO DE DADOS APLICADO À BIG DATA\n",
        "# PROFESSOR: WELLINGTON RODRIGO MONTEIRO\n",
        "# ALUNO: FÁBIO HENRIQUE DOS SANTOS\n",
        "\n"
      ],
      "metadata": {
        "id": "ck3G7EaDphhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elabore as seguintes etapas:\n",
        "1. Mapear cada arquivo como uma tabela dentro do Apache Spark SQL, importando cada um deles.\n",
        "2. Ajustar os tipos de dado correspondentes entre as colunas dos arquivos e das tabelas.\n",
        "\n"
      ],
      "metadata": {
        "id": "VNlqzqxftsWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3.7'\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3.7'"
      ],
      "metadata": {
        "id": "MIE5Ls5Z1UG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrmU_aGo2Ced",
        "outputId": "fb92e11b-40c5-45ca-bae6-3f4edf67601f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 48 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 38.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=3fbb4cdc5e95c91eb73e0264d62b49f78f163f7a5e1f2690f24ccdb9c5e83703\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Banco de dados Aplicado a Big Data\").config(\"spark.some.config.option\",\"some-value\").getOrCreate()"
      ],
      "metadata": {
        "id": "z0iT7NSS159E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext"
      ],
      "metadata": {
        "id": "bqlLsuCZ1-vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load arquivos\n",
        "tbl_endereco = spark.read.option(\"header\",True).option(\"sep\",\";\").csv(\"address.csv\")\n",
        "tbl_city = spark.read.option(\"header\",True).option(\"sep\",\";\").csv(\"city.csv\")\n",
        "tbl_customer = spark.read.option(\"header\",True).option(\"sep\",\";\").csv(\"customer.csv\")\n",
        "tbl_film = spark.read.option(\"header\",True).option(\"sep\",\";\").csv(\"film.csv\")\n",
        "tbl_language = spark.read.option(\"header\",True).option(\"sep\",\";\").csv(\"language.csv\")\n",
        "\n",
        "\n",
        "# Views do SparkSQL\n",
        "tbl_endereco.createOrReplaceTempView(\"tbl_endereco\")\n",
        "tbl_city.createOrReplaceTempView(\"tbl_city\")\n",
        "tbl_customer.createOrReplaceTempView(\"tbl_customer\")\n",
        "tbl_film.createOrReplaceTempView(\"tbl_film\")\n",
        "tbl_language.createOrReplaceTempView(\"tbl_language\")"
      ],
      "metadata": {
        "id": "6A5t7Qad2hQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analises"
      ],
      "metadata": {
        "id": "EdfW2xVdA4fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tbl_endereco.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w-wlK_qAiV7",
        "outputId": "d8f10151-721e-4a26-f657-a937c1e24137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['address_id',\n",
              " 'address',\n",
              " 'address2',\n",
              " 'district',\n",
              " 'city_id',\n",
              " 'postal_code',\n",
              " 'phone',\n",
              " 'location',\n",
              " 'last_update']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tbl_endereco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZba1DyVA7-L",
        "outputId": "9df1decb-b7fb-499d-d8e8-af33e0496c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[address_id: string, address: string, address2: string, district: string, city_id: string, postal_code: string, phone: string, location: string, last_update: string]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"select tbl_language.name from tbl_language\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFDIrbRuBIzq",
        "outputId": "f982964a-a01f-4c5c-9b11-a84191617378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "| English|\n",
            "| Italian|\n",
            "|Japanese|\n",
            "|Mandarin|\n",
            "|  French|\n",
            "|  German|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Elaborar uma consulta para responder à seguinte pergunta:\n",
        "Quantos filmes existem em cada língua/idioma?\n"
      ],
      "metadata": {
        "id": "zLCV5SsvBUME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "select tbl_language.language_id, tbl_language.name, count(*) as filmesEmCadaIdioma\n",
        "from tbl_language, tbl_film\n",
        "where tbl_language.language_id = tbl_film.language_id\n",
        "group by tbl_language.language_id, tbl_language.name\n",
        "order by filmesEmCadaIdioma asc\n",
        "limit 1\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdOjfTfnBXNq",
        "outputId": "dc86bcaf-25ae-43ca-ad21-9bcade47b847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+------------------+\n",
            "|language_id|   name|filmesEmCadaIdioma|\n",
            "+-----------+-------+------------------+\n",
            "|          1|English|              1000|\n",
            "+-----------+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Elaborar uma consulta para responder à seguinte pergunta:\n",
        "Quantos clientes moram na mesma cidade?"
      ],
      "metadata": {
        "id": "ajxV4ZQpBaDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "select \n",
        "    tbl_customer.customer_id , \n",
        "    tbl_customer.first_name,  \n",
        "    tbl_endereco.address_id ,  \n",
        "    tbl_city.city_id, \n",
        "    tbl_city.city, \n",
        "    count(*) as ClientesPorCidade\n",
        "from \n",
        "    tbl_customer, \n",
        "    tbl_endereco, \n",
        "    tbl_city  \n",
        "where \n",
        "    tbl_customer.address_id = tbl_endereco.address_id and tbl_endereco.address_id = tbl_city.city_id\n",
        "    \n",
        "group by \n",
        "    tbl_customer.customer_id, \n",
        "    tbl_customer.first_name, \n",
        "    tbl_endereco.address_id,  \n",
        "    tbl_city.city_id, \n",
        "    tbl_city.city\n",
        "    \n",
        "order by tbl_customer.customer_id asc\n",
        "limit 5\n",
        "\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_ezGwZzBa96",
        "outputId": "eedcfed2-5eda-41a0-e1f5-150ca32c928f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+----------+-------+---------+-----------------+\n",
            "|customer_id|first_name|address_id|city_id|     city|ClientesPorCidade|\n",
            "+-----------+----------+----------+-------+---------+-----------------+\n",
            "|          1|      MARY|         5|      5|    Adana|                1|\n",
            "|         10|   DOROTHY|        14|     14|al-Manama|                1|\n",
            "|        100|     ROBIN|       104|    104|   Cavite|                1|\n",
            "|        101|     PEGGY|       105|    105|  Cayenne|                1|\n",
            "|        102|   CRYSTAL|       106|    106|   Celaya|                1|\n",
            "+-----------+----------+----------+-------+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fim"
      ],
      "metadata": {
        "id": "qSiFehfOBf_a"
      }
    }
  ]
}